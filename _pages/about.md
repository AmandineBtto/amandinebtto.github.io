---
layout: about
title: Home
permalink: /
subtitle: |+ 
          <b>Ph.D. Candidate</b> <br>
          <a href=""> Mines Paris, PSL University </a> <br><br>
          Email: amandine.brunetto[AT]minesparis.psl.eu 

profile:
  align: left
  image: photo_brunetto.png
  image_circular: false # crops the image to make it circular
  # more_info: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---

I'm a final-year PhD student at [PSL Research University](https://psl.eu/en), working at the [Center for Robotics](https://www.caor.minesparis.psl.eu/presentation/perception-and-machine-learning/) at [Mines Paris](https://www.minesparis.psl.eu/). My research focuses on multimodal learning with a focus on how combining the audio and visual modalities can enhance perception.

My passion for audio runs deep—I'm also a musician—which naturally led me to explore how sound interacts with visual information in learning systems. Recently, I worked on NeRAF, a method for implicit acoustic learning based on 3D scenes that generates spatial room impulse responses at novel viewpoints (ICLR 2025). I also contributed to the Audio-Visual Batvision dataset, which addresses depth prediction from robot-generated echoes (IROS 2023).

Broadly, I’m interested in multimodal generation, audio & computer vision, neural implicit learning and increasingly, diffusion models.

In a few months, I’ll be looking for exciting opportunities, either as a research scientist in an industrial lab or in a postdoctoral position, where I can keep pushing the boundaries of multimodal AI. 
Feel free to reach out if you're interested in collaborating, chatting about research, or if you know of opportunities that align with my work.
